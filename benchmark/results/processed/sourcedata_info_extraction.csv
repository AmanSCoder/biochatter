Full model name,Score achieved,Score possible,Score SD,Accuracy,Iterations
gpt-4-0125-preview,68.28081667873946,99.0,0.0,0.6897052189771662,5
gpt-4-0613,66.22137714622475,99.0,0.0,0.6689027994568157,5
gpt-4o-2024-05-13,64.74068171431274,99.0,0.0,0.6539462799425529,5
gpt-3.5-turbo-0613,56.96276507493527,99.0,0.0,0.5753814654033865,5
gpt-3.5-turbo-0125,50.49315772140031,99.0,0.0,0.5100318961757607,5
mistral-instruct-v0.2:7:ggufv2:Q5_K_M,38.18966963891097,99.0,0.0,0.3857542387768785,5
mistral-instruct-v0.2:7:ggufv2:Q3_K_M,36.528391936017044,99.0,0.0,0.3689736559193641,5
mistral-instruct-v0.2:7:ggufv2:Q6_K,36.37381725881603,99.0,0.0,0.3674122955435963,5
mistral-instruct-v0.2:7:ggufv2:Q8_0,34.81674305485256,99.0,0.0,0.351684273281339,5
mistral-instruct-v0.2:7:ggufv2:Q4_K_M,34.3554515360392,99.0,0.0,0.34702476299029494,5
mistral-instruct-v0.2:7:ggufv2:Q2_K,32.79487403841604,99.0,0.0,0.33126135392339434,5
openhermes-2.5:7:ggufv2:Q2_K,0.5618556701030928,2.0,0.0,0.2809278350515464,2
llama-2-chat:70:ggufv2:Q4_K_M,23.852639746180454,99.0,0.0,0.24093575501192377,5
mixtral-instruct-v0.1:46_7:ggufv2:Q5_K_M,23.330238106746446,99.0,0.0,0.23565897077521664,5
mixtral-instruct-v0.1:46_7:ggufv2:Q3_K_M,22.732595584380334,99.0,0.0,0.22962217762000336,5
mixtral-instruct-v0.1:46_7:ggufv2:Q6_K,22.326864100889843,99.0,0.0,0.2255238798069681,5
llama-2-chat:70:ggufv2:Q2_K,21.28965124892795,99.0,0.0,0.21504698231240352,5
llama-2-chat:70:ggufv2:Q5_K_M,20.806434402581186,99.0,0.0,0.21016600406647662,5
llama-2-chat:70:ggufv2:Q3_K_M,19.59185693257297,99.0,0.0,0.19789754477346433,5
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,19.184852561756426,99.0,0.0,0.19378638951269117,5
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,18.72855813548349,99.0,0.0,0.18917735490387363,5
llama-3-instruct:8:ggufv2:Q8_0,18.66689596900119,99.0,0.0,0.18855450473738575,5
chatglm3:6:ggmlv3:q4_0,18.64016536772001,99.0,0.0,0.18828449866383848,5
llama-3-instruct:8:ggufv2:Q5_K_M,16.47694753243307,99.0,0.0,0.1664338134589199,5
llama-3-instruct:8:ggufv2:Q6_K,16.103049640693207,99.0,0.0,0.16265706707770916,5
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,15.593864046664642,99.0,0.0,0.1575137782491378,5
code-llama-instruct:7:ggufv2:Q4_K_M,13.734471627385293,99.0,0.0,0.1387320366402555,5
llama-3-instruct:8:ggufv2:Q4_K_M,11.570274154329585,99.0,0.0,0.11687145610433924,5
llama-2-chat:13:ggufv2:Q3_K_M,11.15042450876327,99.0,0.0,0.11263055059356838,5
llama-2-chat:13:ggufv2:Q4_K_M,8.79788342677711,99.0,0.0,0.08886750936138495,5
llama-2-chat:7:ggufv2:Q4_K_M,8.439692956995263,99.0,0.0,0.08524942380803295,5
llama-2-chat:13:ggufv2:Q5_K_M,7.585048900259881,99.0,0.0,0.07661665555818062,5
llama-2-chat:13:ggufv2:Q8_0,7.548326257472688,99.0,0.0,0.0762457197724514,5
llama-2-chat:7:ggufv2:Q5_K_M,6.9061549937251785,99.0,0.0,0.06975914135075938,5
llama-2-chat:7:ggufv2:Q3_K_M,6.442100051856844,99.0,0.0,0.06507171769552368,5
llama-2-chat:13:ggufv2:Q2_K,6.428949563634648,99.0,0.0,0.06493888448115806,5
llama-2-chat:7:ggufv2:Q2_K,3.582468046776857,99.0,0.0,0.03618654592703896,5
