Full model name,Score achieved,Score possible,Score SD,Accuracy,Iterations
gpt-3.5-turbo-0125,8.0,40.0,0,0.2,5
openhermes-2.5:7:ggufv2:Q6_K,8.0,40.0,0,0.2,5
openhermes-2.5:7:ggufv2:Q3_K_M,9.0,45.0,0,0.2,5
gpt-4o-2024-05-13,8.0,40.0,0,0.2,5
llama-3-instruct:8:ggufv2:Q4_K_M,7.0,36.0,0,0.19444444444444445,5
openhermes-2.5:7:ggufv2:Q8_0,8.0,45.0,0,0.17777777777777778,5
openhermes-2.5:7:ggufv2:Q5_K_M,8.0,45.0,0,0.17777777777777778,5
openhermes-2.5:7:ggufv2:Q4_K_M,8.0,45.0,0,0.17777777777777778,5
gpt-4-0613,8.0,45.0,0,0.17777777777777778,5
gpt-3.5-turbo-0613,8.0,45.0,0,0.17777777777777778,5
llama-3-instruct:8:ggufv2:Q8_0,7.0,40.0,0,0.175,5
llama-3-instruct:8:ggufv2:Q6_K,7.0,40.0,0,0.175,5
llama-3-instruct:8:ggufv2:Q5_K_M,7.0,40.0,0,0.175,5
gpt-4-0125-preview,7.0,45.0,0,0.15555555555555556,5
chatglm3:6:ggmlv3:q4_0,6.0,40.0,0,0.15,5
openhermes-2.5:7:ggufv2:Q2_K,5.0,45.0,0,0.1111111111111111,5
code-llama-instruct:7:ggufv2:Q3_K_M,4.0,40.0,0,0.1,5
mistral-instruct-v0.2:7:ggufv2:Q6_K,4.0,40.0,0,0.1,5
mixtral-instruct-v0.1:46_7:ggufv2:Q6_K,3.8,40.0,0,0.095,5
code-llama-instruct:13:ggufv2:Q3_K_M,3.6,40.0,0,0.09,5
llama-2-chat:70:ggufv2:Q5_K_M,4.0,45.0,0,0.08888888888888889,5
llama-2-chat:7:ggufv2:Q8_0,4.0,45.0,0,0.08888888888888889,5
llama-2-chat:70:ggufv2:Q4_K_M,4.0,45.0,0,0.08888888888888889,5
llama-2-chat:7:ggufv2:Q4_K_M,4.0,45.0,0,0.08888888888888889,5
llama-2-chat:7:ggufv2:Q5_K_M,4.0,45.0,0,0.08888888888888889,5
mistral-instruct-v0.2:7:ggufv2:Q5_K_M,4.0,45.0,0,0.08888888888888889,5
mixtral-instruct-v0.1:46_7:ggufv2:Q5_K_M,3.8,45.0,0,0.08444444444444445,5
llama-2-chat:7:ggufv2:Q6_K,3.0,40.0,0,0.075,5
mistral-instruct-v0.2:7:ggufv2:Q3_K_M,3.0,45.0,0,0.06666666666666667,5
mistral-instruct-v0.2:7:ggufv2:Q4_K_M,3.0,45.0,0,0.06666666666666667,5
llama-2-chat:7:ggufv2:Q3_K_M,3.0,45.0,0,0.06666666666666667,5
mixtral-instruct-v0.1:46_7:ggufv2:Q3_K_M,3.0,45.0,0,0.06666666666666667,5
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,3.0,45.0,0,0.06666666666666667,5
mistral-instruct-v0.2:7:ggufv2:Q8_0,3.0,45.0,0,0.06666666666666667,5
code-llama-instruct:7:ggufv2:Q4_K_M,3.0,45.0,0,0.06666666666666667,5
llama-2-chat:70:ggufv2:Q3_K_M,3.0,45.0,0,0.06666666666666667,5
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,2.8,45.0,0,0.06222222222222222,5
code-llama-instruct:7:ggufv2:Q2_K,2.0,40.0,0,0.05,5
code-llama-instruct:34:ggufv2:Q8_0,2.0,40.0,0,0.05,5
mistral-instruct-v0.2:7:ggufv2:Q2_K,2.0,45.0,0,0.044444444444444446,5
code-llama-instruct:34:ggufv2:Q6_K,1.0,40.0,0,0.025,5
code-llama-instruct:34:ggufv2:Q5_K_M,1.0,40.0,0,0.025,5
code-llama-instruct:7:ggufv2:Q5_K_M,1.0,45.0,0,0.022222222222222223,5
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,0.0,45.0,0,0.0,5
code-llama-instruct:7:ggufv2:Q6_K,0.0,40.0,0,0.0,5
code-llama-instruct:13:ggufv2:Q4_K_M,0.0,40.0,0,0.0,5
code-llama-instruct:13:ggufv2:Q5_K_M,0.0,40.0,0,0.0,5
code-llama-instruct:13:ggufv2:Q6_K,0.0,40.0,0,0.0,5
code-llama-instruct:7:ggufv2:Q8_0,0.0,45.0,0,0.0,5
llama-2-chat:7:ggufv2:Q2_K,0.0,45.0,0,0.0,5
llama-2-chat:13:ggufv2:Q2_K,0.0,45.0,0,0.0,5
code-llama-instruct:13:ggufv2:Q2_K,0.0,40.0,0,0.0,5
llama-2-chat:13:ggufv2:Q4_K_M,0.0,45.0,0,0.0,5
llama-2-chat:13:ggufv2:Q5_K_M,0.0,45.0,0,0.0,5
llama-2-chat:13:ggufv2:Q6_K,0.0,40.0,0,0.0,5
code-llama-instruct:13:ggufv2:Q8_0,0.0,40.0,0,0.0,5
code-llama-instruct:34:ggufv2:Q2_K,0.0,40.0,0,0.0,5
code-llama-instruct:34:ggufv2:Q3_K_M,0.0,40.0,0,0.0,5
code-llama-instruct:34:ggufv2:Q4_K_M,0.0,40.0,0,0.0,5
llama-2-chat:13:ggufv2:Q8_0,0.0,45.0,0,0.0,5
llama-2-chat:70:ggufv2:Q2_K,0.0,45.0,0,0.0,5
llama-2-chat:13:ggufv2:Q3_K_M,0.0,45.0,0,0.0,5
