Full model name,Score achieved,Score possible,Score SD,Accuracy,Iterations
gpt-3.5-turbo-0125,29.0,150.0,0,0.19333333333333333,5
gpt-4-0613,29.0,150.0,0,0.19333333333333333,5
code-llama-instruct:7:ggufv2:Q4_K_M,29.0,150.0,0,0.19333333333333333,5
code-llama-instruct:7:ggufv2:Q5_K_M,28.8,150.0,0,0.192,5
code-llama-instruct:7:ggufv2:Q8_0,28.8,150.0,0,0.192,5
code-llama-instruct:7:ggufv2:Q6_K,28.8,150.0,0,0.192,5
gpt-3.5-turbo-0613,28.4,150.0,0,0.18933333333333333,5
openhermes-2.5:7:ggufv2:Q3_K_M,28.2,150.0,0,0.188,5
openhermes-2.5:7:ggufv2:Q2_K,28.2,150.0,0,0.188,5
llama-3-instruct:8:ggufv2:Q6_K,27.8,150.0,0,0.18533333333333335,5
llama-3-instruct:8:ggufv2:Q5_K_M,27.8,150.0,0,0.18533333333333335,5
llama-3-instruct:8:ggufv2:Q4_K_M,27.6,150.0,0,0.184,5
llama-3-instruct:8:ggufv2:Q8_0,27.6,150.0,0,0.184,5
code-llama-instruct:7:ggufv2:Q2_K,27.6,150.0,0,0.184,5
llama-2-chat:70:ggufv2:Q4_K_M,27.6,150.0,0,0.184,5
openhermes-2.5:7:ggufv2:Q5_K_M,27.4,150.0,0,0.18266666666666664,5
llama-2-chat:70:ggufv2:Q3_K_M,27.2,150.0,0,0.18133333333333332,5
llama-2-chat:70:ggufv2:Q5_K_M,27.2,150.0,0,0.18133333333333332,5
code-llama-instruct:34:ggufv2:Q4_K_M,27.2,150.0,0,0.18133333333333332,5
code-llama-instruct:34:ggufv2:Q5_K_M,27.0,150.0,0,0.18,5
llama-2-chat:70:ggufv2:Q2_K,27.0,150.0,0,0.18,5
mixtral-instruct-v0.1:46_7:ggufv2:Q3_K_M,26.799999999999997,150.0,0,0.17866666666666664,5
openhermes-2.5:7:ggufv2:Q8_0,26.4,150.0,0,0.176,5
openhermes-2.5:7:ggufv2:Q4_K_M,26.2,150.0,0,0.17466666666666666,5
code-llama-instruct:7:ggufv2:Q3_K_M,26.2,150.0,0,0.17466666666666666,5
code-llama-instruct:34:ggufv2:Q8_0,25.8,150.0,0,0.17200000000000001,5
openhermes-2.5:7:ggufv2:Q6_K,25.8,150.0,0,0.17200000000000001,5
code-llama-instruct:34:ggufv2:Q6_K,25.6,150.0,0,0.1706666666666667,5
mistral-instruct-v0.2:7:ggufv2:Q8_0,25.4,150.0,0,0.16933333333333334,5
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,25.4,150.0,0,0.16933333333333334,5
mixtral-instruct-v0.1:46_7:ggufv2:Q5_K_M,25.2,150.0,0,0.16799999999999998,5
gpt-4-0125-preview,25.0,150.0,0,0.16666666666666666,5
code-llama-instruct:13:ggufv2:Q4_K_M,25.0,150.0,0,0.16666666666666666,5
code-llama-instruct:13:ggufv2:Q3_K_M,25.0,150.0,0,0.16666666666666666,5
mistral-instruct-v0.2:7:ggufv2:Q6_K,25.0,150.0,0,0.16666666666666666,5
mixtral-instruct-v0.1:46_7:ggufv2:Q6_K,24.8,150.0,0,0.16533333333333333,5
mistral-instruct-v0.2:7:ggufv2:Q5_K_M,24.8,150.0,0,0.16533333333333333,5
mistral-instruct-v0.2:7:ggufv2:Q4_K_M,24.799999999999997,150.0,0,0.1653333333333333,5
code-llama-instruct:13:ggufv2:Q2_K,24.6,150.0,0,0.164,5
llama-2-chat:13:ggufv2:Q6_K,24.4,150.0,0,0.16266666666666665,5
gpt-4o-2024-05-13,24.0,150.0,0,0.16,5
code-llama-instruct:13:ggufv2:Q6_K,23.8,150.0,0,0.15866666666666668,5
llama-2-chat:13:ggufv2:Q8_0,23.6,150.0,0,0.15733333333333335,5
code-llama-instruct:34:ggufv2:Q3_K_M,23.6,150.0,0,0.15733333333333335,5
code-llama-instruct:13:ggufv2:Q5_K_M,23.4,150.0,0,0.156,5
mistral-instruct-v0.2:7:ggufv2:Q3_K_M,23.2,150.0,0,0.15466666666666667,5
code-llama-instruct:13:ggufv2:Q8_0,23.0,150.0,0,0.15333333333333332,5
llama-2-chat:13:ggufv2:Q4_K_M,22.8,150.0,0,0.152,5
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,22.8,150.0,0,0.152,5
llama-2-chat:13:ggufv2:Q5_K_M,22.4,150.0,0,0.14933333333333332,5
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,21.8,150.0,0,0.14533333333333334,5
mistral-instruct-v0.2:7:ggufv2:Q2_K,20.8,150.0,0,0.13866666666666666,5
llama-2-chat:7:ggufv2:Q3_K_M,20.8,150.0,0,0.13866666666666666,5
code-llama-instruct:34:ggufv2:Q2_K,20.6,150.0,0,0.13733333333333334,5
llama-2-chat:7:ggufv2:Q2_K,20.6,150.0,0,0.13733333333333334,5
llama-2-chat:13:ggufv2:Q3_K_M,20.4,150.0,0,0.13599999999999998,5
llama-2-chat:7:ggufv2:Q6_K,19.8,150.0,0,0.132,5
llama-2-chat:7:ggufv2:Q4_K_M,19.4,150.0,0,0.12933333333333333,5
llama-2-chat:7:ggufv2:Q8_0,19.2,150.0,0,0.128,5
llama-2-chat:7:ggufv2:Q5_K_M,19.0,150.0,0,0.12666666666666668,5
chatglm3:6:ggmlv3:q4_0,16.6,150.0,0,0.11066666666666668,5
llama-2-chat:13:ggufv2:Q2_K,13.0,150.0,0,0.08666666666666667,5
