Full model name,Score achieved,Score possible,Score SD,Accuracy,Iterations
code-llama-instruct:34:ggufv2:Q4_K_M,7.8,40.0,0,0.195,5
code-llama-instruct:34:ggufv2:Q5_K_M,7.6,40.0,0,0.19,5
code-llama-instruct:34:ggufv2:Q8_0,7.4,40.0,0,0.185,5
code-llama-instruct:34:ggufv2:Q6_K,7.2,40.0,0,0.18,5
gpt-4-0613,8.0,45.0,0,0.17777777777777778,5
code-llama-instruct:13:ggufv2:Q2_K,7.0,40.0,0,0.175,5
code-llama-instruct:34:ggufv2:Q3_K_M,7.0,40.0,0,0.175,5
gpt-3.5-turbo-0125,7.8,45.0,0,0.17333333333333334,5
code-llama-instruct:13:ggufv2:Q3_K_M,6.8,40.0,0,0.16999999999999998,5
mixtral-instruct-v0.1:46_7:ggufv2:Q6_K,6.8,40.0,0,0.16999999999999998,5
gpt-4o-2024-05-13,6.8,40.0,0,0.16999999999999998,5
openhermes-2.5:7:ggufv2:Q2_K,7.6,45.0,0,0.1688888888888889,5
code-llama-instruct:13:ggufv2:Q6_K,6.6,40.0,0,0.16499999999999998,5
code-llama-instruct:7:ggufv2:Q3_K_M,7.2,45.0,0,0.16,5
code-llama-instruct:7:ggufv2:Q2_K,6.4,40.0,0,0.16,5
llama-2-chat:70:ggufv2:Q5_K_M,7.0,45.0,0,0.15555555555555556,5
llama-2-chat:13:ggufv2:Q4_K_M,7.0,45.0,0,0.15555555555555556,5
mixtral-instruct-v0.1:46_7:ggufv2:Q3_K_M,7.0,45.0,0,0.15555555555555556,5
llama-2-chat:70:ggufv2:Q3_K_M,7.0,45.0,0,0.15555555555555556,5
openhermes-2.5:7:ggufv2:Q5_K_M,7.0,45.0,0,0.15555555555555556,5
code-llama-instruct:7:ggufv2:Q6_K,6.2,40.0,0,0.155,5
llama-3-instruct:8:ggufv2:Q6_K,6.2,40.0,0,0.155,5
llama-3-instruct:8:ggufv2:Q4_K_M,6.2,40.0,0,0.155,5
code-llama-instruct:13:ggufv2:Q5_K_M,6.2,40.0,0,0.155,5
code-llama-instruct:13:ggufv2:Q4_K_M,6.2,40.0,0,0.155,5
llama-2-chat:13:ggufv2:Q6_K,6.199999999999999,40.0,0,0.15499999999999997,5
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,6.8,45.0,0,0.1511111111111111,5
openhermes-2.5:7:ggufv2:Q4_K_M,6.8,45.0,0,0.1511111111111111,5
llama-2-chat:70:ggufv2:Q4_K_M,6.8,45.0,0,0.1511111111111111,5
openhermes-2.5:7:ggufv2:Q8_0,6.8,45.0,0,0.1511111111111111,5
gpt-3.5-turbo-0613,6.8,45.0,0,0.1511111111111111,5
code-llama-instruct:13:ggufv2:Q8_0,6.0,40.0,0,0.15,5
code-llama-instruct:34:ggufv2:Q2_K,6.0,40.0,0,0.15,5
gpt-4-0125-preview,6.6,45.0,0,0.14666666666666667,5
openhermes-2.5:7:ggufv2:Q6_K,6.6,45.0,0,0.14666666666666667,5
llama-2-chat:13:ggufv2:Q3_K_M,6.6,45.0,0,0.14666666666666667,5
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,6.6000000000000005,45.0,0,0.14666666666666667,5
llama-3-instruct:8:ggufv2:Q8_0,5.8,40.0,0,0.145,5
openhermes-2.5:7:ggufv2:Q3_K_M,7.199999999999999,50.0,0,0.144,5
llama-2-chat:13:ggufv2:Q8_0,6.4,45.0,0,0.14222222222222222,5
mixtral-instruct-v0.1:46_7:ggufv2:Q5_K_M,6.4,45.0,0,0.14222222222222222,5
mistral-instruct-v0.2:7:ggufv2:Q4_K_M,6.2,45.0,0,0.13777777777777778,5
code-llama-instruct:7:ggufv2:Q5_K_M,6.2,45.0,0,0.13777777777777778,5
mistral-instruct-v0.2:7:ggufv2:Q5_K_M,6.2,45.0,0,0.13777777777777778,5
llama-2-chat:7:ggufv2:Q2_K,6.2,45.0,0,0.13777777777777778,5
code-llama-instruct:7:ggufv2:Q8_0,6.0,45.0,0,0.13333333333333333,5
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,6.0,45.0,0,0.13333333333333333,5
llama-2-chat:70:ggufv2:Q2_K,6.0,45.0,0,0.13333333333333333,5
mistral-instruct-v0.2:7:ggufv2:Q3_K_M,6.0,45.0,0,0.13333333333333333,5
mistral-instruct-v0.2:7:ggufv2:Q6_K,5.2,40.0,0,0.13,5
llama-3-instruct:8:ggufv2:Q5_K_M,5.2,40.0,0,0.13,5
mistral-instruct-v0.2:7:ggufv2:Q8_0,5.8,45.0,0,0.1288888888888889,5
llama-2-chat:13:ggufv2:Q5_K_M,5.8,45.0,0,0.1288888888888889,5
mistral-instruct-v0.2:7:ggufv2:Q2_K,5.4,45.0,0,0.12000000000000001,5
code-llama-instruct:7:ggufv2:Q4_K_M,5.4,45.0,0,0.12000000000000001,5
llama-2-chat:7:ggufv2:Q4_K_M,4.4,45.0,0,0.09777777777777778,5
llama-2-chat:7:ggufv2:Q3_K_M,4.2,45.0,0,0.09333333333333334,5
llama-2-chat:7:ggufv2:Q8_0,3.2,45.0,0,0.07111111111111111,5
llama-2-chat:7:ggufv2:Q6_K,3.0,45.0,0,0.06666666666666667,5
llama-2-chat:13:ggufv2:Q2_K,2.6,45.0,0,0.05777777777777778,5
llama-2-chat:7:ggufv2:Q5_K_M,2.6,45.0,0,0.05777777777777778,5
chatglm3:6:ggmlv3:q4_0,2.2,40.0,0,0.05500000000000001,5
