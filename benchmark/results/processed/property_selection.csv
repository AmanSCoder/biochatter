Full model name,Score achieved,Score possible,Score SD,Accuracy,Iterations
gpt-3.5-turbo-0613,23.2,320.0,0,0.0725,5
gpt-4-0613,23.0,320.0,0,0.071875,5
gpt-3.5-turbo-0125,22.8,320.0,0,0.07125000000000001,5
chatglm3:6:ggmlv3:q4_0,18.4,320.0,0,0.057499999999999996,5
llama-3-instruct:8:ggufv2:Q8_0,18.0,320.0,0,0.05625,5
llama-3-instruct:8:ggufv2:Q6_K,18.0,320.0,0,0.05625,5
llama-3-instruct:8:ggufv2:Q5_K_M,12.0,320.0,0,0.0375,5
llama-2-chat:70:ggufv2:Q3_K_M,11.0,320.0,0,0.034375,5
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,10.4,320.0,0,0.0325,5
openhermes-2.5:7:ggufv2:Q8_0,8.0,320.0,0,0.025,5
openhermes-2.5:7:ggufv2:Q5_K_M,8.0,320.0,0,0.025,5
openhermes-2.5:7:ggufv2:Q3_K_M,8.0,320.0,0,0.025,5
llama-3-instruct:8:ggufv2:Q4_K_M,7.0,320.0,0,0.021875,5
llama-2-chat:7:ggufv2:Q3_K_M,6.4,320.0,0,0.02,5
mixtral-instruct-v0.1:46_7:ggufv2:Q3_K_M,4.199999999999999,320.0,0,0.013124999999999998,5
code-llama-instruct:7:ggufv2:Q2_K,4.0,320.0,0,0.0125,5
mistral-instruct-v0.2:7:ggufv2:Q6_K,3.0,320.0,0,0.009375,5
openhermes-2.5:7:ggufv2:Q6_K,3.0,320.0,0,0.009375,5
openhermes-2.5:7:ggufv2:Q4_K_M,3.0,320.0,0,0.009375,5
mistral-instruct-v0.2:7:ggufv2:Q3_K_M,3.0,320.0,0,0.009375,5
llama-2-chat:7:ggufv2:Q5_K_M,2.4,320.0,0,0.0075,5
mistral-instruct-v0.2:7:ggufv2:Q8_0,2.4,320.0,0,0.0075,5
code-llama-instruct:13:ggufv2:Q5_K_M,0.0,320.0,0,0.0,5
code-llama-instruct:13:ggufv2:Q4_K_M,0.0,320.0,0,0.0,5
code-llama-instruct:13:ggufv2:Q3_K_M,0.0,320.0,0,0.0,5
mistral-instruct-v0.2:7:ggufv2:Q2_K,0.0,320.0,0,0.0,5
mistral-instruct-v0.2:7:ggufv2:Q4_K_M,0.0,320.0,0,0.0,5
mistral-instruct-v0.2:7:ggufv2:Q5_K_M,0.0,320.0,0,0.0,5
code-llama-instruct:7:ggufv2:Q3_K_M,0.0,320.0,0,0.0,5
llama-2-chat:7:ggufv2:Q8_0,0.0,320.0,0,0.0,5
code-llama-instruct:34:ggufv2:Q8_0,0.0,320.0,0,0.0,5
mixtral-instruct-v0.1:46_7:ggufv2:Q5_K_M,0.0,320.0,0,0.0,5
mixtral-instruct-v0.1:46_7:ggufv2:Q6_K,0.0,320.0,0,0.0,5
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,0.0,320.0,0,0.0,5
openhermes-2.5:7:ggufv2:Q2_K,0.0,320.0,0,0.0,5
code-llama-instruct:34:ggufv2:Q6_K,0.0,320.0,0,0.0,5
code-llama-instruct:34:ggufv2:Q5_K_M,0.0,320.0,0,0.0,5
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,0.0,320.0,0,0.0,5
llama-2-chat:7:ggufv2:Q6_K,0.0,320.0,0,0.0,5
code-llama-instruct:7:ggufv2:Q4_K_M,0.0,320.0,0,0.0,5
llama-2-chat:13:ggufv2:Q3_K_M,0.0,320.0,0,0.0,5
code-llama-instruct:7:ggufv2:Q5_K_M,0.0,320.0,0,0.0,5
code-llama-instruct:7:ggufv2:Q6_K,0.0,320.0,0,0.0,5
code-llama-instruct:7:ggufv2:Q8_0,0.0,320.0,0,0.0,5
code-llama-instruct:34:ggufv2:Q2_K,0.0,320.0,0,0.0,5
code-llama-instruct:13:ggufv2:Q8_0,0.0,320.0,0,0.0,5
gpt-4-0125-preview,0.0,320.0,0,0.0,5
code-llama-instruct:13:ggufv2:Q6_K,0.0,320.0,0,0.0,5
gpt-4o-2024-05-13,0.0,320.0,0,0.0,5
llama-2-chat:13:ggufv2:Q2_K,0.0,320.0,0,0.0,5
llama-2-chat:13:ggufv2:Q4_K_M,0.0,320.0,0,0.0,5
llama-2-chat:7:ggufv2:Q4_K_M,0.0,320.0,0,0.0,5
llama-2-chat:13:ggufv2:Q5_K_M,0.0,320.0,0,0.0,5
llama-2-chat:13:ggufv2:Q6_K,0.0,320.0,0,0.0,5
llama-2-chat:13:ggufv2:Q8_0,0.0,320.0,0,0.0,5
llama-2-chat:70:ggufv2:Q2_K,0.0,320.0,0,0.0,5
code-llama-instruct:13:ggufv2:Q2_K,0.0,320.0,0,0.0,5
llama-2-chat:70:ggufv2:Q4_K_M,0.0,320.0,0,0.0,5
llama-2-chat:70:ggufv2:Q5_K_M,0.0,320.0,0,0.0,5
llama-2-chat:7:ggufv2:Q2_K,0.0,320.0,0,0.0,5
code-llama-instruct:34:ggufv2:Q4_K_M,0.0,320.0,0,0.0,5
code-llama-instruct:34:ggufv2:Q3_K_M,0.0,320.0,0,0.0,5
