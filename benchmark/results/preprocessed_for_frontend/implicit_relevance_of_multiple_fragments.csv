Full model name,Passed test cases,Total test cases,Accuracy,Iterations
chatglm3:6:ggmlv3:q4_0,2.0,2.0,1.0,2
gpt-3.5-turbo,2.0,2.0,1.0,2
openhermes-2.5:7:ggufv2:Q5_K_M,2.0,2.0,1.0,1
openhermes-2.5:7:ggufv2:Q4_K_M,2.0,2.0,1.0,2
mixtral-instruct-v0.1:46_7:ggufv2:Q6_K,2.0,2.0,1.0,2
mixtral-instruct-v0.1:46_7:ggufv2:Q5_K_M,2.0,2.0,1.0,1
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,2.0,2.0,1.0,2
mixtral-instruct-v0.1:46_7:ggufv2:Q4_0,2.0,2.0,1.0,2
mistral-instruct-v0.2:7:ggufv2:Q5_K_M,2.0,2.0,1.0,1
mistral-instruct-v0.2:7:ggufv2:Q4_K_M,2.0,2.0,1.0,1
mistral-instruct-v0.2:7:ggufv2:Q3_K_M,2.0,2.0,1.0,1
llama-2-chat:13:ggufv2:Q2_K,2.0,2.0,1.0,2
gpt-4,2.0,2.0,1.0,2
llama-2-chat:70:ggufv2:Q4_K_M,2.0,2.0,1.0,2
openhermes-2.5:7:ggufv2:Q8_0,2.0,2.0,1.0,2
code-llama-instruct:7:ggufv2:Q4_K_M,2.0,2.0,1.0,2
code-llama-instruct:7:ggufv2:Q3_K_M,2.0,2.0,1.0,1
code-llama-instruct:34:ggufv2:Q5_K_M,2.0,2.0,1.0,1
code-llama-instruct:34:ggufv2:Q2_K,2.0,2.0,1.0,2
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,1.5,2.0,0.75,2
code-llama-instruct:7:ggufv2:Q2_K,1.5,2.0,0.75,2
code-llama-instruct:34:ggufv2:Q8_0,1.5,2.0,0.75,2
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,1.5,2.0,0.75,2
llama-2-chat:13:ggufv2:Q4_K_S,1.5,2.0,0.75,2
llama-2-chat:7:ggufv2:Q5_K_M,1.5,2.0,0.75,2
llama-2-chat:70:ggufv2:Q5_K_M,1.5,2.0,0.75,2
llama-2-chat:7:ggufv2:Q8_0,1.0,2.0,0.5,2
mistral-instruct-v0.2:7:ggufv2:Q2_K,1.0,2.0,0.5,1
mistral-instruct-v0.2:7:ggufv2:Q8_0,1.0,2.0,0.5,1
mixtral-instruct-v0.1:46_7:ggufv2:Q5_0,1.0,2.0,0.5,2
mixtral-instruct-v0.1:46_7:ggufv2:Q3_K_M,1.0,2.0,0.5,2
code-llama-instruct:34:ggufv2:Q3_K_M,1.0,2.0,0.5,1
code-llama-instruct:13:ggufv2:Q8_0,1.0,2.0,0.5,2
code-llama-instruct:13:ggufv2:Q5_K_M,1.0,2.0,0.5,1
openhermes-2.5:7:ggufv2:Q2_K,1.0,2.0,0.5,2
openhermes-2.5:7:ggufv2:Q3_K_M,1.0,2.0,0.5,1
code-llama-instruct:13:ggufv2:Q4_K_M,1.0,2.0,0.5,2
llama-2-chat:7:ggufv2:Q6_K,1.0,2.0,0.5,2
code-llama-instruct:7:ggufv2:Q5_K_M,1.0,2.0,0.5,1
llama-2-chat:7:ggufv2:Q5_0,1.0,2.0,0.5,2
code-llama-instruct:7:ggufv2:Q8_0,1.0,2.0,0.5,2
llama-2-chat:13:ggufv2:Q3_K_M,1.0,2.0,0.5,2
llama-2-chat:13:ggufv2:Q4_0,1.0,2.0,0.5,2
llama-2-chat:13:ggufv2:Q4_1,1.0,2.0,0.5,2
llama-2-chat:13:ggufv2:Q4_K_M,1.0,2.0,0.5,2
llama-2-chat:13:ggufv2:Q5_0,1.0,2.0,0.5,2
llama-2-chat:13:ggufv2:Q5_K_M,1.0,2.0,0.5,2
llama-2-chat:13:ggufv2:Q6_K,1.0,2.0,0.5,2
llama-2-chat:13:ggufv2:Q8_0,1.0,2.0,0.5,2
llama-2-chat:70:ggufv2:Q2_K,1.0,2.0,0.5,2
llama-2-chat:70:ggufv2:Q3_K_M,1.0,2.0,0.5,2
llama-2-chat:7:ggufv2:Q2_K,1.0,2.0,0.5,2
llama-2-chat:7:ggufv2:Q3_K_M,1.0,2.0,0.5,2
llama-2-chat:7:ggufv2:Q4_0,1.0,2.0,0.5,2
llama-2-chat:7:ggufv2:Q4_1,1.0,2.0,0.5,2
llama-2-chat:7:ggufv2:Q4_K_M,1.0,2.0,0.5,2
llama-2-chat:7:ggufv2:Q4_K_S,1.0,2.0,0.5,2
code-llama-instruct:13:ggufv2:Q2_K,0.5,2.0,0.25,2
code-llama-instruct:34:ggufv2:Q4_K_M,0.5,2.0,0.25,2
code-llama-instruct:13:ggufv2:Q3_K_M,0.0,2.0,0.0,2
