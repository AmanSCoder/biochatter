Model name,Size,Quantisation,Mean,SD
gpt-3.5-turbo,NA,NA,0.88,0.16
llama-2-chat,7,q3_K_M,0.52,0.34
llama-2-chat,7,q5_0,0.49,0.32
llama-2-chat,7,q5_K_M,0.47,0.38
llama-2-chat,13,q5_0,0.46,0.53
llama-2-chat,7,q4_0,0.45,0.39
llama-2-chat,7,q4_K_S,0.44,0.37
llama-2-chat,13,q4_1,0.43,0.48
llama-2-chat,7,q4_1,0.42,0.35
llama-2-chat,13,q4_0,0.41,0.4
llama-2-chat,7,q4_K_M,0.41,0.35
llama-2-chat,7,q8_0,0.4,0.34
llama-2-chat,13,q5_K_M,0.4,0.43
llama-2-chat,13,q4_K_S,0.38,0.39
llama-2-chat,13,q8_0,0.38,0.4
llama-2-chat,13,q4_K_M,0.38,0.4
llama-2-chat,13,q6_K,0.38,0.4
llama-2-chat,7,q6_K,0.36,0.34
mixtral-instruct-v0.1,"46,7",Q2_K,0.35,0.39
mixtral-instruct-v0.1,"46,7",Q4_0,0.35,0.38
mixtral-instruct-v0.1,"46,7",Q4_K_M,0.35,0.37
llama-2-chat,13,q3_K_M,0.34,0.35
mixtral-instruct-v0.1,"46,7",Q5_0,0.33,0.28
llama-2-chat,7,q2_K,0.33,0.3
llama-2-chat,13,q2_K,0.3,0.4
mixtral-instruct-v0.1,"46,7",Q8_0,0.28,0.34
