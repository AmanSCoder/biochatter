Model name,Mean
llama-2-chat:7:ggmlv3:q2_K,inf
gpt-3.5-turbo,0.8777573529411764
llama-2-chat:7:ggmlv3:q3_K_M,0.51640625
llama-2-chat:7:ggmlv3:q5_0,0.4864583333333333
llama-2-chat:7:ggmlv3:q5_K_M,0.465625
llama-2-chat:13:ggmlv3:q5_0,0.4609375
llama-2-chat:7:ggmlv3:q4_0,0.45
llama-2-chat:7:ggmlv3:q4_K_S,0.4447916666666667
llama-2-chat:13:ggmlv3:q4_1,0.4296875
llama-2-chat:7:ggmlv3:q4_1,0.415625
llama-2-chat:13:ggmlv3:q4_0,0.4078125
llama-2-chat:7:ggmlv3:q4_K_M,0.4075520833333333
llama-2-chat:7:ggmlv3:q8_0,0.403125
llama-2-chat:13:ggmlv3:q5_K_M,0.3984375
llama-2-chat:13:ggmlv3:q4_K_S,0.3802083333333333
llama-2-chat:13:ggmlv3:q6_K,0.3776041666666667
llama-2-chat:13:ggmlv3:q4_K_M,0.3776041666666667
llama-2-chat:13:ggmlv3:q8_0,0.3776041666666667
llama-2-chat:7:ggmlv3:q6_K,0.35703125
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,0.35026041666666663
mixtral-instruct-v0.1:46_7:ggufv2:Q4_0,0.34895833333333337
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,0.34791666666666665
llama-2-chat:13:ggmlv3:q2_K,0.34226190476190477
llama-2-chat:13:ggmlv3:q3_K_M,0.3359375
mixtral-instruct-v0.1:46_7:ggufv2:Q5_0,0.33125
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,0.28125
