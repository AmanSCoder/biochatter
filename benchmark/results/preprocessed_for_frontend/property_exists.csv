Full model name,Passed test cases,Total test cases,Accuracy,Iterations
openhermes-2.5:7:ggufv2:Q8_0,4.0,4.0,1.0,2
llama-2-chat:70:ggufv2:Q2_K,4.0,4.0,1.0,2
code-llama-instruct:13:ggufv2:Q4_K_M,4.0,4.0,1.0,2
code-llama-instruct:13:ggufv2:Q8_0,4.0,4.0,1.0,2
code-llama-instruct:34:ggufv2:Q4_K_M,4.0,4.0,1.0,2
code-llama-instruct:34:ggufv2:Q8_0,4.0,4.0,1.0,2
code-llama-instruct:7:ggufv2:Q4_K_M,4.0,4.0,1.0,2
gpt-3.5-turbo,4.0,4.0,1.0,2
gpt-4,4.0,4.0,1.0,2
code-llama-instruct:13:ggufv2:Q2_K,4.0,4.0,1.0,2
llama-2-chat:70:ggufv2:Q4_K_M,4.0,4.0,1.0,2
code-llama-instruct:7:ggufv2:Q2_K,3.5,4.0,0.875,2
code-llama-instruct:7:ggufv2:Q8_0,3.5,4.0,0.875,2
openhermes-2.5:7:ggufv2:Q2_K,3.5,4.0,0.875,2
openhermes-2.5:7:ggufv2:Q4_K_M,4.0,5.0,0.8,2
llama-2-chat:13:ggufv2:Q4_K_M,3.0,4.0,0.75,2
code-llama-instruct:34:ggufv2:Q2_K,3.0,4.0,0.75,2
llama-2-chat:7:ggufv2:Q4_K_M,3.5,5.0,0.7,2
llama-2-chat:13:ggufv2:Q8_0,2.5,4.0,0.625,2
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,2.5,4.0,0.625,2
llama-2-chat:7:ggufv2:Q8_0,2.0,4.0,0.5,2
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,2.0,4.0,0.5,2
llama-2-chat:7:ggufv2:Q2_K,1.5,4.0,0.375,2
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,1.5,4.0,0.375,2
llama-2-chat:13:ggufv2:Q2_K,0.0,4.0,0.0,2
chatglm3:6:ggmlv3:q4_0,0.0,4.0,0.0,2
