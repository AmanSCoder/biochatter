Full model name,Passed test cases,Total test cases,Score,Iterations
mixtral-instruct-v0.1:46_7:ggufv2:Q6_K,12.0,16.0,0.75,2
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,12.0,16.0,0.75,2
gpt-4,12.0,16.0,0.75,2
mixtral-instruct-v0.1:46_7:ggufv2:Q4_0,12.0,16.0,0.75,2
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,12.0,16.0,0.75,2
mixtral-instruct-v0.1:46_7:ggufv2:Q5_0,12.0,16.0,0.75,2
mixtral-instruct-v0.1:46_7:ggufv2:Q3_K_M,12.0,16.0,0.75,2
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,11.5,16.0,0.71875,2
llama-2-chat:13:ggufv2:Q5_0,11.0,16.0,0.6875,2
llama-2-chat:13:ggufv2:Q4_K_M,11.0,16.0,0.6875,2
llama-2-chat:13:ggufv2:Q5_K_M,11.0,16.0,0.6875,2
llama-2-chat:13:ggufv2:Q3_K_M,11.0,16.0,0.6875,2
llama-2-chat:13:ggufv2:Q4_1,11.0,16.0,0.6875,2
gpt-3.5-turbo,11.0,16.0,0.6875,2
llama-2-chat:13:ggufv2:Q8_0,11.0,16.0,0.6875,2
llama-2-chat:13:ggufv2:Q6_K,11.0,16.0,0.6875,2
llama-2-chat:7:ggufv2:Q6_K,10.5,16.0,0.65625,2
llama-2-chat:7:ggufv2:Q3_K_M,10.5,16.0,0.65625,2
llama-2-chat:13:ggufv2:Q4_K_S,10.0,16.0,0.625,2
openhermes-2.5:7:ggufv2:Q2_K,10.0,16.0,0.625,2
openhermes-2.5:7:ggufv2:Q4_K_M,10.0,16.0,0.625,2
llama-2-chat:7:ggufv2:Q4_1,10.0,16.0,0.625,2
llama-2-chat:7:ggufv2:Q4_K_S,10.0,16.0,0.625,2
llama-2-chat:7:ggufv2:Q5_0,10.0,16.0,0.625,2
llama-2-chat:7:ggufv2:Q5_K_M,10.0,16.0,0.625,2
llama-2-chat:7:ggufv2:Q8_0,10.0,16.0,0.625,2
llama-2-chat:7:ggufv2:Q4_K_M,9.5,16.0,0.59375,2
openhermes-2.5:7:ggufv2:Q8_0,9.0,16.0,0.5625,2
llama-2-chat:70:ggufv2:Q3_K_M,9.0,16.0,0.5625,2
llama-2-chat:70:ggufv2:Q2_K,9.0,16.0,0.5625,2
llama-2-chat:13:ggufv2:Q4_0,9.0,16.0,0.5625,2
llama-2-chat:13:ggufv2:Q2_K,9.0,16.0,0.5625,2
llama-2-chat:70:ggufv2:Q5_K_M,8.0,16.0,0.5,2
llama-2-chat:70:ggufv2:Q4_K_M,8.0,16.0,0.5,2
llama-2-chat:7:ggufv2:Q4_0,8.0,16.0,0.5,2
llama-2-chat:7:ggufv2:Q2_K,7.0,16.0,0.4375,2
