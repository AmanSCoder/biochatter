Full model name,Passed test cases,Total test cases,Accuracy,Iterations
gpt-4,16.0,16.0,1.0,2
openhermes-2.5:7:ggufv2:Q2_K,16.0,16.0,1.0,2
openhermes-2.5:7:ggufv2:Q3_K_M,16.0,16.0,1.0,1
openhermes-2.5:7:ggufv2:Q5_K_M,16.0,16.0,1.0,1
gpt-3.5-turbo,16.0,16.0,1.0,2
code-llama-instruct:7:ggufv2:Q5_K_M,14.0,16.0,0.875,1
openhermes-2.5:7:ggufv2:Q4_K_M,14.0,16.0,0.875,2
code-llama-instruct:13:ggufv2:Q2_K,14.0,16.0,0.875,2
llama-2-chat:13:ggufv2:Q8_0,14.0,16.0,0.875,2
llama-2-chat:13:ggufv2:Q5_K_M,14.0,16.0,0.875,1
llama-2-chat:13:ggufv2:Q4_K_M,14.0,16.0,0.875,2
llama-2-chat:13:ggufv2:Q3_K_M,14.0,16.0,0.875,1
mistral-instruct-v0.2:7:ggufv2:Q5_K_M,14.0,16.0,0.875,1
code-llama-instruct:7:ggufv2:Q8_0,14.0,16.0,0.875,2
openhermes-2.5:7:ggufv2:Q8_0,14.0,16.0,0.875,2
code-llama-instruct:7:ggufv2:Q4_K_M,14.0,16.0,0.875,2
code-llama-instruct:34:ggufv2:Q3_K_M,14.0,16.0,0.875,1
code-llama-instruct:13:ggufv2:Q3_K_M,14.0,16.0,0.875,2
code-llama-instruct:13:ggufv2:Q4_K_M,14.0,16.0,0.875,2
code-llama-instruct:7:ggufv2:Q3_K_M,14.0,16.0,0.875,1
code-llama-instruct:13:ggufv2:Q8_0,14.0,16.0,0.875,2
code-llama-instruct:13:ggufv2:Q5_K_M,14.0,16.0,0.875,2
code-llama-instruct:34:ggufv2:Q4_K_M,14.0,16.0,0.875,2
code-llama-instruct:34:ggufv2:Q5_K_M,14.0,16.0,0.875,1
code-llama-instruct:34:ggufv2:Q8_0,14.0,16.0,0.875,2
code-llama-instruct:7:ggufv2:Q2_K,14.0,16.0,0.875,2
mistral-instruct-v0.2:7:ggufv2:Q8_0,14.0,16.0,0.875,1
code-llama-instruct:34:ggufv2:Q2_K,13.0,16.0,0.8125,2
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,13.0,16.0,0.8125,2
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,13.0,16.0,0.8125,2
llama-2-chat:7:ggufv2:Q5_K_M,13.0,16.0,0.8125,1
llama-2-chat:7:ggufv2:Q8_0,13.0,16.0,0.8125,2
mixtral-instruct-v0.1:46_7:ggufv2:Q3_K_M,13.0,16.0,0.8125,1
llama-2-chat:7:ggufv2:Q4_K_M,12.5,16.0,0.78125,2
llama-2-chat:70:ggufv2:Q2_K,12.0,16.0,0.75,2
mistral-instruct-v0.2:7:ggufv2:Q4_K_M,12.0,16.0,0.75,1
mistral-instruct-v0.2:7:ggufv2:Q3_K_M,12.0,16.0,0.75,1
llama-2-chat:7:ggufv2:Q3_K_M,12.0,16.0,0.75,1
llama-2-chat:70:ggufv2:Q5_K_M,12.0,16.0,0.75,1
llama-2-chat:70:ggufv2:Q4_K_M,12.0,16.0,0.75,2
llama-2-chat:70:ggufv2:Q3_K_M,12.0,16.0,0.75,1
mixtral-instruct-v0.1:46_7:ggufv2:Q5_K_M,11.0,16.0,0.6875,1
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,10.5,16.0,0.65625,2
llama-2-chat:7:ggufv2:Q2_K,10.0,16.0,0.625,2
mistral-instruct-v0.2:7:ggufv2:Q2_K,9.0,16.0,0.5625,1
chatglm3:6:ggmlv3:q4_0,5.5,16.0,0.34375,2
llama-2-chat:13:ggufv2:Q2_K,3.0,16.0,0.1875,2
